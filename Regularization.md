# Regularization

Regularization is a technique to avoid overfitting when it comes up in a deep learning model. This way, the model can learn the pattern without learning the noise (which is the goal of machine learning frameworks).

### Common Regularization Techniques are:
- [[Early Stopping]]
- [[Batch Normalization]]
- [[l_1 and l_2 Regularization]]
- [[Dropout]]
- [[Max-Norm Regularization]]